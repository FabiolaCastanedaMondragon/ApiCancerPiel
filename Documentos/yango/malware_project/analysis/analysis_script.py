import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import numpy as np
# El módulo 'os' ya no es necesario para la ruta, pero lo dejamos por si se usa en otro lado.
# import os 


def run_malware_analysis():
    """
    Carga datos, entrena un modelo Random Forest,
    y devuelve el accuracy, el dataset y los datos para la gráfica de separabilidad ESCALADA.
    """
    
    # 1. Cargar datos (MODIFICADO PARA USAR LA URL DE DRIVE)
    
    # URL de descarga directa de tu dataset en Google Drive
    DATASET_URL = 'https://drive.google.com/uc?export=download&id=1xZHWDN0FgEq9HrphZpiL9ewQaJcc8ur7'

    try:
        # **AQUÍ ESTÁ EL CAMBIO CLAVE:** Pandas lee el CSV directamente desde la URL.
        # Eliminamos la lógica de rutas locales (base_dir, file_path, os.path.exists).
        df = pd.read_csv(DATASET_URL)
        df.columns = df.columns.str.strip()
        
    except Exception as e:
        # Si falla la descarga o la lectura, lanzamos un error que la vista 'api_malware_results' capturará.
        raise RuntimeError(f"Fallo al cargar el dataset desde la URL de Drive: {str(e)}")

    # 2. Limpieza (Igual que antes)
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.fillna(0, inplace=True)

    target = 'calss'
    features = ['duration', 'total_fpackets', 'total_bpktl']
    # ... (El resto de la lógica de tu función permanece sin cambios)
    
    if target not in df.columns:
        raise ValueError(f"Columna objetivo '{target}' no encontrada.")
    missing = [f for f in features if f not in df.columns]
    if missing:
        raise ValueError(f"Faltan columnas: {missing}")

    y = df[target].factorize()[0]
    X = df[features]

    # 3. División y escalado
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Extraer las columnas de prueba escaladas para la gráfica
    idx_duration = features.index('duration')
    idx_fpackets = features.index('total_fpackets')
    X_test_duration_scaled = X_test_scaled[:, idx_duration]
    X_test_fpackets_scaled = X_test_scaled[:, idx_fpackets]


    # 4. Entrenar modelo
    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)

    # 5. Crear malla para frontera de decisión (USANDO RANGO ESCALADO)
    
    # Usar los rangos de los datos de prueba ESCALADOS
    x_min_scaled, x_max_scaled = X_test_duration_scaled.min(), X_test_duration_scaled.max()
    y_min_scaled, y_max_scaled = X_test_fpackets_scaled.min(), X_test_fpackets_scaled.max()
    
    # Crear malla con valores escalados
    xx_scaled, yy_scaled = np.meshgrid(np.linspace(x_min_scaled, x_max_scaled, 100),
                                       np.linspace(y_min_scaled, y_max_scaled, 100))

    # Reconstruir el grid de 3 características escaladas para la predicción
    grid_scaled_array = np.zeros((xx_scaled.size, len(features)))
    grid_scaled_array[:, idx_duration] = xx_scaled.ravel()
    grid_scaled_array[:, idx_fpackets] = yy_scaled.ravel()
    
    # Rellenar la tercera característica ('total_bpktl') con su valor medio ESCALADO
    mean_scaled_bpktl = X_train_scaled[:, features.index('total_bpktl')].mean()
    grid_scaled_array[:, features.index('total_bpktl')] = mean_scaled_bpktl

    # Predecir la probabilidad de ser clase 1 (Malware)
    zz = model.predict_proba(grid_scaled_array)[:, 1].reshape(xx_scaled.shape)

    # 6. Salida final
    df_sample = df.head(10).to_dict('records')

    return {
        'accuracy': round(accuracy, 8),
        'dataframe': df_sample,
        'separabilityData': {
            # ENVIAMOS LOS RANGOS ESCALADOS
            'xx': xx_scaled.tolist(),
            'yy': yy_scaled.tolist(),
            'zz': zz.tolist(),
            # ENVIAMOS LOS PUNTOS DE PRUEBA ESCALADOS
            'x_points': X_test_duration_scaled.tolist(),
            'y_points': X_test_fpackets_scaled.tolist(),
            'labels': y_test.tolist()
        }
    }